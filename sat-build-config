#!/usr/bin/env python3
"""
sat-build-config (MVP)

Executable placed at:
    tools/sat-build-config

Discovers plugins under:
    tools/plugins/

Automatically determines SAT root based on its own location.
"""

import argparse
import sys
from pathlib import Path
from typing import Any, Dict, Optional

# ------------------------------------------------------------
# Import YAML safely
# ------------------------------------------------------------
try:
    import yaml
except ImportError:
    print("[sat-build-config] ERROR: PyYAML is required (pip install pyyaml)", file=sys.stderr)
    sys.exit(1)

# ------------------------------------------------------------
# Utility functions
# ------------------------------------------------------------

def load_yaml_file(path: Path) -> Optional[Dict[str, Any]]:
    """Load a YAML file safely."""
    if not path.exists():
        return None
    try:
        with path.open("r", encoding="utf-8") as f:
            return yaml.safe_load(f) or {}
    except Exception as exc:
        print(f"[sat-build-config] ERROR: reading YAML file {path}: {exc}", file=sys.stderr)
        sys.exit(1)


def deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
    """Recursive merge of dictionaries."""
    for key, val in override.items():
        if (
            key in base
            and isinstance(base[key], dict)
            and isinstance(val, dict)
        ):
            base[key] = deep_merge(base[key], val)
        else:
            base[key] = val
    return base


def ensure_dict(value: Any) -> Dict[str, Any]:
    """Normalize non-dict values to dicts."""
    return value if isinstance(value, dict) else {}

# ------------------------------------------------------------
# Plugin loading
# ------------------------------------------------------------

def load_core_plugin_defaults(sat_root: Path, plugin_rel: str, plugin_id: str, required=True):
    """
    Load defaults for a core plugin located at:
        tools/sat-build-config
        tools/plugins/<plugin_rel>/
    """
    plugin_dir = sat_root / "tools" / "plugins" / plugin_rel
    plugin_yml = plugin_dir / "plugin.yml"
    defaults_yml = plugin_dir / "etc" / "defaults.yml"

    # plugin.yml missing
    if not plugin_yml.exists():
        msg = f"[sat-build-config] {'ERROR' if required else 'WARN'}: Missing plugin.yml for {plugin_id} at {plugin_dir}"
        print(msg, file=sys.stderr)
        if required:
            sys.exit(1)
        return {}

    plugin_meta = load_yaml_file(plugin_yml) or {}
    if plugin_meta.get("id") != plugin_id:
        print(
            f"[sat-build-config] WARN: plugin id mismatch for {plugin_dir}. "
            f"Expected '{plugin_id}', got '{plugin_meta.get('id')}'.",
            file=sys.stderr,
        )

    # defaults.yml missing
    if not defaults_yml.exists():
        msg = f"[sat-build-config] {'ERROR' if required else 'WARN'}: Missing etc/defaults.yml for {plugin_id}"
        print(msg, file=sys.stderr)
        if required:
            sys.exit(1)
        return {}

    data = load_yaml_file(defaults_yml) or {}
    defaults = data.get("defaults", {})
    fragments = defaults.get("config_fragments", {})

    if not isinstance(fragments, dict):
        print(
            f"[sat-build-config] WARN: config_fragments for {plugin_id} is not a dict; ignoring.",
            file=sys.stderr,
        )
        return {}

    return fragments


def load_all_plugin_config_fragments(plugins_root: Path) -> Dict[str, Any]:
    """
    Discover all plugins that ship etc/defaults.yml and merge their
    defaults.config_fragments into a single config dict.

    plugins_root is the base 'plugins' directory.
    """
    config: Dict[str, Any] = {}

    # Collect all defaults.yml paths under plugins/**/etc/defaults.yml
    defaults_files = sorted(plugins_root.glob("**/etc/defaults.yml"))

    # Optional: core plugins first (simple path-based rule)
    core_files = [p for p in defaults_files if "/core/" in str(p)]
    other_files = [p for p in defaults_files if "/core/" not in str(p)]
    ordered_files = core_files + other_files

    for defaults_file in ordered_files:
        data = load_yaml_file(defaults_file) or {}

        fragments = (
            data.get("defaults", {})
                .get("config_fragments", {})
            or {}
        )

        if fragments:
            config = deep_merge(config, fragments)

    return config


# ------------------------------------------------------------
# Template expansion
# ------------------------------------------------------------

def expand_templates(config: Dict[str, Any]) -> None:
    """MVP: expand ../{{ archive_identity.id }}"""
    ai = ensure_dict(config.get("archive_identity"))
    archive_id = ai.get("id")

    if not archive_id:
        return

    root = ai.get("archive_root")
    if isinstance(root, str) and "{{ archive_identity.id }}" in root:
        ai["archive_root"] = root.replace("{{ archive_identity.id }}", str(archive_id))

    config["archive_identity"] = ai

# ------------------------------------------------------------
# Validation
# ------------------------------------------------------------

def validate_config(config: Dict[str, Any]) -> None:
    errors = []
    if not config.get("schema_version"):
        errors.append("Missing: schema_version")

    ai = ensure_dict(config.get("archive_identity"))
    if not ai.get("id"):
        errors.append("Missing: archive_identity.id")
    if not ai.get("archive_root"):
        errors.append("Missing: archive_identity.archive_root")

    if errors:
        print("[sat-build-config] ERROR: invalid configuration:", file=sys.stderr)
        for e in errors:
            print("  -", e, file=sys.stderr)
        sys.exit(1)

# ------------------------------------------------------------
# Core build function
# ------------------------------------------------------------

def build_config(args) -> Dict[str, Any]:
    config: Dict[str, Any] = {}

    # SAT root = directory containing "tools/"
    sat_root = Path(__file__).resolve().parents[1]

    # Load core.schema
    schema = load_core_plugin_defaults(
        sat_root, "core/schema", "core.schema", required=True
    )
    config = deep_merge(config, schema)

    # Load core.archive-identity
    archive_id = load_core_plugin_defaults(
        sat_root, "core/archive-identity", "core.archive-identity", required=True
    )
    config = deep_merge(config, archive_id)

    # Load defaults from all plugins (including core + non-core)
    plugins_root = sat_root / "tools" / "plugins"
    plugin_fragments = load_all_plugin_config_fragments(plugins_root)
    config = deep_merge(config, plugin_fragments)

    # Optional: archive-level config
    if args.config:
        cfg_path = Path(args.config)
        archive_cfg = load_yaml_file(cfg_path)
        if archive_cfg is None:
            print(f"[sat-build-config] ERROR: --config file not found: {cfg_path}", file=sys.stderr)
            sys.exit(1)
        if not isinstance(archive_cfg, dict):
            print(f"[sat-build-config] ERROR: --config must be a YAML mapping", file=sys.stderr)
            sys.exit(1)
        config = deep_merge(config, archive_cfg)

    # CLI overrides
    ai = ensure_dict(config.get("archive_identity"))

    if args.archive_id:
        ai["id"] = args.archive_id
    if args.archive_label:
        ai["label"] = args.archive_label
    if args.archive_description:
        ai["description"] = args.archive_description
    if args.archive_root:
        ai["archive_root"] = args.archive_root

    config["archive_identity"] = ai

    # Expand templates
    expand_templates(config)

    # Validate
    validate_config(config)

    return config

# ------------------------------------------------------------
# CLI
# ------------------------------------------------------------

def parse_args():
    p = argparse.ArgumentParser(
        prog="sat-build-config",
        description="Assemble the SAT archive configuration (MVP)."
    )

    p.add_argument("--config", help="Archive-level config file")
    p.add_argument("--archive-id", help="Override archive_identity.id")
    p.add_argument("--archive-label", help="Override archive_identity.label")
    p.add_argument("--archive-description", help="Override archive_identity.description")
    p.add_argument("--archive-root", help="Override archive_identity.archive_root")
    p.add_argument("--output", "-o", help="Write YAML output to file")

    return p.parse_args()

def main():
    args = parse_args()
    config = build_config(args)

    yaml_text = yaml.safe_dump(
        config,
        sort_keys=False,
        allow_unicode=True,
        default_flow_style=False,
        indent=2,
    )

    if args.output:
        out = Path(args.output)
        out.parent.mkdir(parents=True, exist_ok=True)
        out.write_text(yaml_text, encoding="utf-8")
    else:
        sys.stdout.write(yaml_text)

if __name__ == "__main__":
    main()
